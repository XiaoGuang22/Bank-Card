"""
é“¶è¡Œå¡å·ç è¯†åˆ«CRNNæ¨¡å‹è®­ç»ƒè„šæœ¬
ä½¿ç”¨CTCæŸå¤±å‡½æ•°è¿›è¡Œç«¯åˆ°ç«¯çš„åºåˆ—è¯†åˆ«è®­ç»ƒ
"""

import os
import csv
import torch
from config import *
from model import CRNN
import torch.optim as optim
from torch.nn import CTCLoss
from evaluate import evaluate
from torch.utils.data import DataLoader
from .dataset import CardDataset, cardnumber_collate_fn


def train_batch(crnn, data, optimizer, criterion, device):
    """
    è®­ç»ƒå•ä¸ªbatchçš„æ•°æ®
    
    Args:
        crnn: CRNNæ¨¡å‹å®ä¾‹
        data: åŒ…å«(images, targets, target_lengths)çš„è®­ç»ƒæ•°æ®
        optimizer: ä¼˜åŒ–å™¨
        criterion: CTCæŸå¤±å‡½æ•°
        device: è®¡ç®—è®¾å¤‡(cpu/gpu)
    
    Returns:
        float: å½“å‰batchçš„å¹³å‡æŸå¤±å€¼
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    crnn.train()
    
    # å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    images, targets, target_lengths = [d.to(device) for d in data]

    # å‰å‘ä¼ æ’­ï¼šé€šè¿‡CRNNæ¨¡å‹è·å–é¢„æµ‹ç»“æœ
    logits = crnn(images)
    # å¯¹è¾“å‡ºè¿›è¡Œlog_softmaxå¤„ç†ï¼Œç”¨äºCTCæŸå¤±è®¡ç®—
    log_probs = torch.nn.functional.log_softmax(logits, dim=2)

    # è·å–batchå¤§å°
    batch_size = images.size(0)
    # åˆ›å»ºè¾“å…¥åºåˆ—é•¿åº¦å¼ é‡(æ‰€æœ‰æ ·æœ¬çš„åºåˆ—é•¿åº¦ç›¸åŒ)
    input_lengths = torch.LongTensor([logits.size(0)] * batch_size)
    # å±•å¹³ç›®æ ‡é•¿åº¦å¼ é‡
    target_lengths = torch.flatten(target_lengths)

    # è®¡ç®—CTCæŸå¤±
    loss = criterion(log_probs, targets, input_lengths, target_lengths)

    # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
    optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦
    loss.backward()        # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
    optimizer.step()       # æ›´æ–°æ¨¡å‹å‚æ•°
    
    return loss.item()  # è¿”å›æŸå¤±å€¼

def main():
    """
    ä¸»è®­ç»ƒå‡½æ•°
    è´Ÿè´£åˆå§‹åŒ–æ¨¡å‹ã€æ•°æ®åŠ è½½å™¨ã€ä¼˜åŒ–å™¨ç­‰ï¼Œå¹¶æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹
    """
    # ==================== è®¾å¤‡é…ç½® ====================
    # è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„è®¡ç®—è®¾å¤‡(ä¼˜å…ˆä½¿ç”¨GPU)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'ä½¿ç”¨è®¾å¤‡: {device}')
    
    # ==================== æ•°æ®åŠ è½½ ====================
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
    train_dataset = CardDataset(
        image_dir=data_dir+'/train', 
        mode='train',
        img_height=img_height, 
        img_width=img_width
    )
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=train_batch_size,
        shuffle=True,                    # æ¯ä¸ªepochéšæœºæ‰“ä¹±æ•°æ®
        num_workers=num_workers,         # æ•°æ®åŠ è½½çš„å¹¶è¡Œè¿›ç¨‹æ•°
        collate_fn=cardnumber_collate_fn # è‡ªå®šä¹‰çš„æ‰¹å¤„ç†å‡½æ•°
    )
    
    # ==================== æ¨¡å‹åˆå§‹åŒ– ====================
    # è®¡ç®—ç±»åˆ«æ•°é‡(å­—ç¬¦æ•° + 1ä¸ªç©ºç™½ç¬¦)
    num_class = len(CardDataset.LABEL2CHAR) + 1
    
    # åˆ›å»ºCRNNæ¨¡å‹å®ä¾‹
    crnn = CRNN(
        img_channel=1,                    # è¾“å…¥å›¾åƒé€šé“æ•°(ç°åº¦å›¾)
        img_height=img_height,            # å›¾åƒé«˜åº¦
        img_width=img_width,              # å›¾åƒå®½åº¦
        num_class=num_class,              # è¾“å‡ºç±»åˆ«æ•°
        map_to_seq_hidden=map_to_seq_hidden,  # CNNåˆ°RNNçš„æ˜ å°„å±‚éšè—å•å…ƒæ•°
        rnn_hidden=rnn_hidden,            # RNNéšè—å•å…ƒæ•°
        leaky_relu=leaky_relu,            # æ˜¯å¦ä½¿ç”¨LeakyReLUæ¿€æ´»å‡½æ•°
        backbone=backbone                 # éª¨å¹²ç½‘ç»œç±»å‹(LCNet/ResNet/MobileNet)
    )
    print('CRNNæ¨¡å‹ç»“æ„:')
    print(crnn)

    # å¦‚æœæŒ‡å®šäº†é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼Œåˆ™åŠ è½½é¢„è®­ç»ƒæƒé‡
    if reload_checkpoint:
        print(f'åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {reload_checkpoint}')
        crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    crnn.to(device)
    
    # ==================== ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•° ====================
    # æ ¹æ®é…ç½®é€‰æ‹©ä¼˜åŒ–å™¨
    if optim_config == 'adam':
        optimizer = optim.Adam(crnn.parameters(), lr=lr)
        print(f'ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡: {lr}')
    elif optim_config == 'sgd':
        optimizer = optim.SGD(crnn.parameters(), lr=lr)
        print(f'ä½¿ç”¨SGDä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡: {lr}')
    elif optim_config == 'rmsprop':
        optimizer = optim.RMSprop(crnn.parameters(), lr=lr)
        print(f'ä½¿ç”¨RMSpropä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡: {lr}')
    
    # åˆ›å»ºCTCæŸå¤±å‡½æ•°
    criterion = CTCLoss(reduction='sum')  # ä½¿ç”¨sum reductionè®¡ç®—æ€»æŸå¤±
    criterion.to(device)

    # ==================== è®­ç»ƒçŠ¶æ€åˆå§‹åŒ– ====================
    best_accuracy = -1      # è®°å½•æœ€ä½³å‡†ç¡®ç‡
    best_epoch = None       # è®°å½•æœ€ä½³å‡†ç¡®ç‡å¯¹åº”çš„epoch
    data = []               # å­˜å‚¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡æ•°æ®
    
    # ==================== åˆ›å»ºä¿å­˜ç›®å½• ====================
    # åˆ›å»ºä¸»ä¿å­˜ç›®å½•
    if not os.path.exists('./runs/recognition'):
        os.mkdir('./runs/recognition')
    
    # è‡ªåŠ¨ç”Ÿæˆæ–°çš„è¿è¡Œç¼–å·ï¼Œé¿å…è¦†ç›–ä¹‹å‰çš„è®­ç»ƒç»“æœ
    run = 1
    while os.path.exists('./runs/recognition/run'+str(run)):
        run += 1
    
    # åˆ›å»ºå½“å‰è¿è¡Œçš„ä¿å­˜ç›®å½•
    os.mkdir('./runs/recognition/run'+str(run))
    os.mkdir('./runs/recognition/run'+str(run)+'/checkpoints')  # æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
    save_path = './runs/recognition/run'+str(run)
    print(f'è®­ç»ƒç»“æœå°†ä¿å­˜åˆ°: {save_path}')

    # ==================== å¼€å§‹è®­ç»ƒå¾ªç¯ ====================
    print(f'å¼€å§‹è®­ç»ƒï¼Œæ€»epochæ•°: {epochs}')
    for epoch in range(1, epochs + 1):
        print(f'\n========== Epoch {epoch}/{epochs} ==========')
        
        # åˆå§‹åŒ–å½“å‰epochçš„ç»Ÿè®¡å˜é‡
        total_train_loss = 0.      # ç´¯è®¡è®­ç»ƒæŸå¤±
        total_train_count = 0      # ç´¯è®¡è®­ç»ƒæ ·æœ¬æ•°
        index = 1                  # å½“å‰batchç´¢å¼•
        length = len(train_loader) # æ€»batchæ•°
        
        # ==================== è®­ç»ƒä¸€ä¸ªepoch ====================
        print('å¼€å§‹è®­ç»ƒ...')
        for train_data in train_loader: 
            # è®­ç»ƒå½“å‰batch
            loss = train_batch(crnn, train_data, optimizer, criterion, device)
            
            # ç»Ÿè®¡æŸå¤±å’Œæ ·æœ¬æ•°
            train_size = train_data[0].size(0)  # å½“å‰batchçš„æ ·æœ¬æ•°
            total_train_loss += loss
            total_train_count += train_size
            
            # æ˜¾ç¤ºå½“å‰batchçš„è®­ç»ƒè¿›åº¦å’ŒæŸå¤±
            print(f'è®­ç»ƒè¿›åº¦ [{index:3d}/{length:3d}] - å¹³å‡æŸå¤±: {loss/train_size:.6f}', end="\r")
            index += 1
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºå½“å‰epochçš„å¹³å‡è®­ç»ƒæŸå¤±
        avg_train_loss = total_train_loss / total_train_count
        print(f'\nEpoch {epoch} å¹³å‡è®­ç»ƒæŸå¤±: {avg_train_loss:.6f}')
        
        # ==================== å‡†å¤‡ä¿å­˜è®­ç»ƒæ•°æ® ====================
        # åˆå§‹åŒ–å½“å‰epochçš„æŒ‡æ ‡è®°å½•
        temp = []
        temp.append(epoch)                    # epochç¼–å·
        temp.append(avg_train_loss)           # å¹³å‡è®­ç»ƒæŸå¤±

        # ==================== ä¿å­˜å½“å‰æ¨¡å‹ ====================
        # ä¿å­˜å½“å‰epochçš„æ¨¡å‹æƒé‡(ç”¨äºæ¢å¤è®­ç»ƒ)
        torch.save(crnn.state_dict(), save_path + '/checkpoints/crnn last.pt')
        print(f'å·²ä¿å­˜å½“å‰æ¨¡å‹åˆ°: {save_path}/checkpoints/crnn last.pt')
        
        # ==================== æ¨¡å‹è¯„ä¼° ====================
        print('å¼€å§‹è¯„ä¼°æ¨¡å‹æ€§èƒ½...')
        # åœ¨éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
        test_loss, accuracy, val_loss, val_accu = evaluate(crnn, data_dir)
        
        # è®°å½•è¯„ä¼°æŒ‡æ ‡
        temp.append(val_loss)    # éªŒè¯é›†æŸå¤±
        temp.append(val_accu)    # éªŒè¯é›†å‡†ç¡®ç‡
        temp.append(test_loss)   # æµ‹è¯•é›†æŸå¤±
        temp.append(accuracy)    # æµ‹è¯•é›†å‡†ç¡®ç‡
        data.append(temp)        # æ·»åŠ åˆ°æ€»æ•°æ®ä¸­
        
        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
        print('========== è¯„ä¼°ç»“æœ ==========')
        print(f'éªŒè¯é›†æŸå¤±: {val_loss:.6f}')
        print(f'éªŒè¯é›†å‡†ç¡®ç‡: {val_accu:.4f}')
        print(f'æµ‹è¯•é›†æŸå¤±: {test_loss:.6f}')
        print(f'æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}')

        # ==================== ä¿å­˜è®­ç»ƒè®°å½• ====================
        # å°†è®­ç»ƒæŒ‡æ ‡ä¿å­˜åˆ°CSVæ–‡ä»¶ä¸­
        with open(save_path + '/results.csv', 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['epoch','train_loss','val_loss', 'val_accu', 'test_loss', 'accuracy'])
            writer.writerows(data)
        print(f'è®­ç»ƒè®°å½•å·²ä¿å­˜åˆ°: {save_path}/results.csv')
        
        # ==================== æ¨¡å‹ä¿å­˜ç­–ç•¥ ====================
        # å¦‚æœå½“å‰æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡è¶…è¿‡å†å²æœ€ä½³ï¼Œåˆ™ä¿å­˜ä¸ºæœ€ä½³æ¨¡å‹
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_epoch = epoch
            torch.save(crnn.state_dict(), save_path + '/checkpoints/crnn best.pt')
            print(f'ğŸ‰ å‘ç°æ›´å¥½çš„æ¨¡å‹! å‡†ç¡®ç‡: {accuracy:.4f}')
            print(f'æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}/checkpoints/crnn best.pt')
        else:
            print(f'å½“å‰å‡†ç¡®ç‡: {accuracy:.4f}, å†å²æœ€ä½³: {best_accuracy:.4f}')
        
        # ==================== æ—©åœç­–ç•¥ ====================
        # å¦‚æœè¿ç»­å¤šä¸ªepochæ²¡æœ‰æ”¹å–„ï¼Œåˆ™æå‰åœæ­¢è®­ç»ƒ
        if epoch - best_epoch > early_stop:
            print(f'â¹ï¸  æ—©åœè§¦å‘! è¿ç»­ {early_stop} ä¸ªepochæ²¡æœ‰æ”¹å–„')
            print(f'æœ€ä½³epoch: {best_epoch}, å½“å‰epoch: {epoch}')
            break

    # ==================== è®­ç»ƒå®Œæˆ ====================
    print('\n========== è®­ç»ƒå®Œæˆ ==========')
    print(f'æœ€ä½³epoch: {best_epoch}')
    print(f'æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}')
    print(f'è®­ç»ƒç»“æœä¿å­˜åœ¨: {save_path}')


if __name__ == '__main__':
    """
    ç¨‹åºå…¥å£ç‚¹
    å½“ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ—¶ï¼Œæ‰§è¡Œä¸»è®­ç»ƒå‡½æ•°
    """
    main()